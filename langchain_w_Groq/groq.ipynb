{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "139c4037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in /home/sudip/miniconda3/envs/gdg/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/sudip/miniconda3/envs/gdg/lib/python3.10/site-packages (from groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/sudip/miniconda3/envs/gdg/lib/python3.10/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/sudip/miniconda3/envs/gdg/lib/python3.10/site-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/sudip/miniconda3/envs/gdg/lib/python3.10/site-packages (from groq) (2.5.3)\n",
      "Requirement already satisfied: sniffio in /home/sudip/miniconda3/envs/gdg/lib/python3.10/site-packages (from groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/sudip/miniconda3/envs/gdg/lib/python3.10/site-packages (from groq) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/sudip/miniconda3/envs/gdg/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/sudip/miniconda3/envs/gdg/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\n",
      "Requirement already satisfied: certifi in /home/sudip/miniconda3/envs/gdg/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/sudip/miniconda3/envs/gdg/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/sudip/miniconda3/envs/gdg/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/sudip/miniconda3/envs/gdg/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /home/sudip/miniconda3/envs/gdg/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (2.14.6)\n",
      "Requirement already satisfied: python-dotenv in /home/sudip/miniconda3/envs/gdg/lib/python3.10/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "#Install necessary libraries\n",
    "!pip install groq\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b0ec7b9-9dc3-4fe0-ab5b-70f591a870d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a28ea8-7cd8-4322-966a-b4f3315ddc0b",
   "metadata": {},
   "source": [
    "## OpenSource LLM Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8624dc27-e0c9-4d3a-b33b-a9636cfc3c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can utilize a Large Language Model (LLM) by integrating it into your application or workflow to generate text, answer questions, or provide language translations.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import os\n",
    "\n",
    "# Initialize the client with the API key\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "# Create chat completions with a system prompt\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that always provides a single sentence as answer\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How can I utilise an LLM?\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\", temperature = 0.5\n",
    ")\n",
    "\n",
    "# Print the response from the assistant\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b2424",
   "metadata": {},
   "source": [
    "# Asking LLM to provide output in a fixed format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac2ea74-f19a-457e-9cea-ca6a101c8ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why is Iceland green and Greenland white?' punchline='Because one is greener and the other is land!' awesome='True' rating=7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import Optional, Union, Dict\n",
    "from groq import Groq\n",
    "\n",
    "# Define the structured output class with more flexible types\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Facts to tell user.\"\"\"\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "    awesome: Union[str, int, bool] = Field(description=\"Explanation of the joke\")\n",
    "    rating: Optional[Union[int, Dict[str, int]]] = Field(description=\"How funny the joke is, from 1 to 10 or a detailed rating dictionary\")\n",
    "\n",
    "def invoke_chat_completion(prompt: str) -> Optional[Joke]:\n",
    "    # Initialize the client with the API key\n",
    "    client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "    # Create chat completions with the user input\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant. Provide the response in JSON format with the following keys: setup, punchline, awesome, rating.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\",\n",
    "    )\n",
    "\n",
    "    # Extract the response from the assistant\n",
    "    response_content = chat_completion.choices[0].message.content\n",
    "    #print(\"Raw response content:\", response_content)\n",
    "\n",
    "    try:\n",
    "        # Parse the JSON response\n",
    "        joke_data = json.loads(response_content)\n",
    "\n",
    "        # Ensure the parsed data is a dictionary\n",
    "        if not isinstance(joke_data, dict):\n",
    "            raise ValueError(\"Parsed JSON is not a dictionary\")\n",
    "\n",
    "        # Convert boolean to string if necessary\n",
    "        if isinstance(joke_data.get('awesome'), bool):\n",
    "            joke_data['awesome'] = str(joke_data['awesome'])\n",
    "        # Convert integer to string if necessary\n",
    "        elif isinstance(joke_data.get('awesome'), int):\n",
    "            joke_data['awesome'] = str(joke_data['awesome'])\n",
    "\n",
    "        # Validate and create the Joke instance\n",
    "        joke = Joke(\n",
    "            setup=joke_data['setup'],\n",
    "            punchline=joke_data['punchline'],\n",
    "            awesome=joke_data['awesome'],\n",
    "            rating=joke_data.get('rating')\n",
    "        )\n",
    "\n",
    "        return joke\n",
    "    except (json.JSONDecodeError, ValidationError, ValueError) as e:\n",
    "        print(\"Failed to parse response or validation error:\", e)\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Why is Iceland green and Greenland white?\"\n",
    "joke = invoke_chat_completion(prompt)\n",
    "if joke:\n",
    "    print(joke)\n",
    "else:\n",
    "    print(\"Failed to retrieve a valid joke.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68456dd5",
   "metadata": {},
   "source": [
    "## Real time streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24e77554-8184-40c2-8618-4675a687ab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In celestial harmony, they dance and play,\n",
      "The Sun, the Moon, and the Goons, in a cosmic sway.\n",
      "The Sun, a fiery ball of light and might,\n",
      "Bringing warmth to the world, banishing the night.\n",
      "\n",
      "The Moon, a glowing orb of gentle beam,\n",
      "Illuminating dreams, and making hearts serene.\n",
      "The Goons, a mischievous trio, full of glee,\n",
      "Causing chaos and laughter, wherever they be.\n",
      "\n",
      "With rays of sunshine, the Goons take flight,\n",
      "Their antics and pranks, a wondrous, cosmic sight.\n",
      "They chase the Moon, with a playful shout,\n",
      "As she hides behind clouds, with a gentle pout.\n",
      "\n",
      "The Sun, a watchful guardian, shines so bright,\n",
      "Keeping the Goons in line, with a gentle might.\n",
      "It guides them on their way, through the starry night,\n",
      "As they frolic and play, with a celestial delight.\n",
      "\n",
      "The Moon, a gentle mother, watches over all,\n",
      "With a loving gaze, that soothes the heart's great fall.\n",
      "She whispers secrets, to the Goons, so dear,\n",
      "And they listen closely, with a reverent ear.\n",
      "\n",
      "Together, the three, create a cosmic show,\n",
      "A dance of light and laughter, that the world may know.\n",
      "Their harmony and joy, a celestial treat,\n",
      "A symphony of wonder, that can't be beat.\n",
      "\n",
      "The Sun, the Moon, and the Goons, a trio divine,\n",
      "A celestial family, that's truly sublime.\n",
      "Their love and laughter, a gift to us all,\n",
      "A reminder to cherish, the beauty that stands tall.\n",
      "\n",
      "So let us bask in the sunshine, and dance in the night,\n",
      "With the Goons and the Moon, in a celestial delight.\n",
      "For in their harmony, we find our own glee,\n",
      "A sense of wonder, that's meant to be.None"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import os\n",
    "\n",
    "# Initialize the client with the API key\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "# Function to invoke chat completion\n",
    "def invoke_chat_completion(topic: str):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant. Write a 100 line poem about the given topic.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Write a poem about {topic}\"\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-70b-8192\",\n",
    "        temperature=0, \n",
    "        stream= True\n",
    "    )\n",
    "\n",
    "    # Stream the response\n",
    "    for chunk in chat_completion:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "\n",
    "# Example usage\n",
    "topic = \"Sun moon and the goons\"\n",
    "invoke_chat_completion(topic)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
